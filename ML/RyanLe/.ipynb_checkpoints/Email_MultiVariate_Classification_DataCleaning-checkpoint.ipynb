{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supposed-vessel",
   "metadata": {},
   "source": [
    "# Data Cleaning Entron Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-repository",
   "metadata": {},
   "source": [
    "Credit to user ankur561999 for this \n",
    "https://www.kaggle.com/ankur561999/data-cleaning-enron-email-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "allied-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import multiprocessing\n",
    "import seaborn as sns\n",
    "import email\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file location\n",
    "entron_email_dir = \"/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/Dataset/emails.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(entron_email_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data exploration\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[1]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = df.loc[1]['message']\n",
    "e = email.message_from_string(message)\n",
    "\n",
    "e.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get_payload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting headers\n",
    "\n",
    "# now we add those fields into our 'df' dataframe\n",
    "def get_field(field, messages):\n",
    "    column = []\n",
    "    for message in messages:\n",
    "        e = email.message_from_string(message)\n",
    "        column.append(e.get(field))\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = get_field(\"Date\", df['message'])\n",
    "df['subject'] = get_field(\"Subject\", df['message'])\n",
    "df['X-Folder'] = get_field(\"X-Folder\", df['message'])\n",
    "df['X-From'] = get_field(\"X-From\", df['message'])\n",
    "df['X-To'] = get_field(\"X-To\", df['message'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract email body \n",
    "def body(messages):\n",
    "    column = []\n",
    "    for message in messages:\n",
    "        e = email.message_from_string(message)\n",
    "        column.append(e.get_payload())\n",
    "    return column\n",
    "\n",
    "df['body'] = body(df['message'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract employee names\n",
    "df['file'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding employee column\n",
    "\n",
    "def employee(file):\n",
    "    column = []\n",
    "    for string in file:\n",
    "        column.append(string.split(\"/\")[0])\n",
    "    return column\n",
    "\n",
    "df['employee'] = employee(df['file'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of folders: \", df.shape[0])\n",
    "print(\"Number of unique folders: \", df['X-Folder'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_emails = pd.DataFrame(df['X-Folder'].value_counts())\n",
    "unique_emails.reset_index(inplace=True)\n",
    "\n",
    "unique_emails.columns = ['folder_name', 'count']\n",
    "# top 20 folders\n",
    "unique_emails.iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 20 folders\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='count', y='folder_name', data=unique_emails.iloc[:20, :], palette=\"Blues_d\")\n",
    "plt.title(\"Top 20 folders\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Folder_Name\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 20 email senders\n",
    "top_20 = pd.DataFrame(df['employee'].value_counts()[:20])\n",
    "top_20.reset_index(inplace=True)\n",
    "top_20.columns = [\"Employee_name\", \"Counts\"]\n",
    "top_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar chart visualization of 20 highest email senders\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "sns.barplot(y=\"Employee_name\", x=\"Counts\", data=top_20, palette=\"Blues_d\")\n",
    "plt.title(\"Top 20 highest email sender employee\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Employee_name\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "# this is sample example\n",
    "x = parser.parse(\"Fri, 4 May 2001 13:51:00 -0700 (PDT)\")\n",
    "print(x.strftime(\"%d-%m-%Y %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformatting the dates\n",
    "\n",
    "def change_type(dates):\n",
    "    column = []\n",
    "    \n",
    "    for date in dates:\n",
    "        column.append(parser.parse(date).strftime(\"%d-%m-%Y %H:%M:%S\"))\n",
    "    return column\n",
    "\n",
    "df['date'] = change_type(df['date'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting df[\"X-Folder\"]\n",
    "def preprocess_folder(folders):\n",
    "    column = []\n",
    "    for folder in folders:\n",
    "        if (folder is None or folder == \"\"):\n",
    "            column.append(np.nan)\n",
    "        else:\n",
    "            column.append(folder.split(\"\\\\\")[-1].lower())\n",
    "    return column\n",
    "\n",
    "df['X-Folder'] = preprocess_folder(df['X-Folder'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique folders\n",
    "print(\"Unique Folders: \", len(df['X-Folder'].unique()))\n",
    "\n",
    "# view some of them\n",
    "df['X-Folder'].unique()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty cells with NaN\n",
    "def replace_empty_with_nan(subject):\n",
    "    column = []\n",
    "    for val in subject:\n",
    "        if (val == \"\"):\n",
    "            column.append(np.nan) \n",
    "        else:\n",
    "            column.append(val)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject'] = replace_empty_with_nan(df['subject'])\n",
    "df['X-To'] = replace_empty_with_nan(df['X-To'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percentage of missing values\n",
    "miss = df.isnull().sum()\n",
    "miss = miss[miss>0]\n",
    "miss = miss / df.shape[0]\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing value rows\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df.isnull().sum(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unneeded columns\n",
    "cols_to_drop = ['file','message','employee']\n",
    "df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "df.to_csv(\"/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/CS4440_project/ML/RyanLe/Dataset/cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting csv into a CSV with 50 columns\n",
    "in_csv = \"/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/CS4440_project/ML/RyanLe/Dataset/cleaned_data.csv\"\n",
    "\n",
    "#get the number of lines of the csv file to be read\n",
    "\n",
    "number_lines = 50 \n",
    "\n",
    "#size of rows of data to write to the csv, \n",
    "rowsize = 50\n",
    "for i in range(1,number_lines,rowsize):\n",
    "    df = pd.read_csv(in_csv,header=None, nrows = rowsize, skiprows = i) #skip rows that have been read\n",
    "    out_csv = 'fifty_emails.csv'\n",
    "    df.to_csv(out_csv, index=False, header=False,  mode='a', chunksize=rowsize)#size of data to append for each loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-hypothesis",
   "metadata": {},
   "source": [
    "## Data Proprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brief-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://www.kaggle.com/ankur561999/enron-email-classification-using-machine-learning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "early-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = \"/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/Dataset/cleaned_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "through-breast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-08-2000 04:03:00</td>\n",
       "      <td>Re: regulatory filing summary</td>\n",
       "      <td>'sent mail</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Colleen Sullivan</td>\n",
       "      <td>Colleen,\\n\\n Please add Mike Grigsby to the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-08-2000 01:58:00</td>\n",
       "      <td>Re: Evaluation for new trading application</td>\n",
       "      <td>'sent mail</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Bruce Ferrell</td>\n",
       "      <td>Bruce,\\n\\nCan you stop by and set up my reuter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24-08-2000 02:48:00</td>\n",
       "      <td>Re: receipts</td>\n",
       "      <td>'sent mail</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>\"Lucy Gonzalez\" &lt;stagecoachmama@hotmail.com&gt; @...</td>\n",
       "      <td>Lucy,\\n I got your email with the attachment. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23-08-2000 08:23:00</td>\n",
       "      <td>Re: ENA Fileplan Project - Needs your approval</td>\n",
       "      <td>'sent mail</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Ina Rangel</td>\n",
       "      <td>you have my approval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23-08-2000 07:09:00</td>\n",
       "      <td>Re: checkbook and budget</td>\n",
       "      <td>'sent mail</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>\"Lucy Gonzalez\" &lt;stagecoachmama@hotmail.com&gt; @...</td>\n",
       "      <td>Lucy,\\n\\n We can discuss your email later.  Ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                         subject  \\\n",
       "0  25-08-2000 04:03:00                   Re: regulatory filing summary   \n",
       "1  25-08-2000 01:58:00      Re: Evaluation for new trading application   \n",
       "2  24-08-2000 02:48:00                                    Re: receipts   \n",
       "3  23-08-2000 08:23:00  Re: ENA Fileplan Project - Needs your approval   \n",
       "4  23-08-2000 07:09:00                        Re: checkbook and budget   \n",
       "\n",
       "     X-Folder           X-From  \\\n",
       "0  'sent mail  Phillip K Allen   \n",
       "1  'sent mail  Phillip K Allen   \n",
       "2  'sent mail  Phillip K Allen   \n",
       "3  'sent mail  Phillip K Allen   \n",
       "4  'sent mail  Phillip K Allen   \n",
       "\n",
       "                                                X-To  \\\n",
       "0                                   Colleen Sullivan   \n",
       "1                                      Bruce Ferrell   \n",
       "2  \"Lucy Gonzalez\" <stagecoachmama@hotmail.com> @...   \n",
       "3                                         Ina Rangel   \n",
       "4  \"Lucy Gonzalez\" <stagecoachmama@hotmail.com> @...   \n",
       "\n",
       "                                                body  \n",
       "0  Colleen,\\n\\n Please add Mike Grigsby to the di...  \n",
       "1  Bruce,\\n\\nCan you stop by and set up my reuter...  \n",
       "2  Lucy,\\n I got your email with the attachment. ...  \n",
       "3                               you have my approval  \n",
       "4  Lucy,\\n\\n We can discuss your email later.  Ho...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading pd, ignoring rid of first 50 rows\n",
    "df = pd.read_csv(cleaned_dataset, skiprows=range(1, 51))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "offensive-porcelain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-08-2000 04:03:00</td>\n",
       "      <td>'sent mail</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Colleen Sullivan</td>\n",
       "      <td>regulatory filing summary colleen please add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-08-2000 01:58:00</td>\n",
       "      <td>'sent mail</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Bruce Ferrell</td>\n",
       "      <td>evaluation new trading application bruce stop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24-08-2000 02:48:00</td>\n",
       "      <td>'sent mail</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>\"Lucy Gonzalez\" &lt;stagecoachmama@hotmail.com&gt; @...</td>\n",
       "      <td>receipts lucy got email attachment let work t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23-08-2000 08:23:00</td>\n",
       "      <td>'sent mail</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Ina Rangel</td>\n",
       "      <td>ena fileplan project needs approval approval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23-08-2000 07:09:00</td>\n",
       "      <td>'sent mail</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>\"Lucy Gonzalez\" &lt;stagecoachmama@hotmail.com&gt; @...</td>\n",
       "      <td>checkbook budget lucy discuss email later pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date    X-Folder           X-From  \\\n",
       "0  25-08-2000 04:03:00  'sent mail  Phillip K Allen   \n",
       "1  25-08-2000 01:58:00  'sent mail  Phillip K Allen   \n",
       "2  24-08-2000 02:48:00  'sent mail  Phillip K Allen   \n",
       "3  23-08-2000 08:23:00  'sent mail  Phillip K Allen   \n",
       "4  23-08-2000 07:09:00  'sent mail  Phillip K Allen   \n",
       "\n",
       "                                                X-To  \\\n",
       "0                                   Colleen Sullivan   \n",
       "1                                      Bruce Ferrell   \n",
       "2  \"Lucy Gonzalez\" <stagecoachmama@hotmail.com> @...   \n",
       "3                                         Ina Rangel   \n",
       "4  \"Lucy Gonzalez\" <stagecoachmama@hotmail.com> @...   \n",
       "\n",
       "                                                text  \n",
       "0   regulatory filing summary colleen please add ...  \n",
       "1   evaluation new trading application bruce stop...  \n",
       "2   receipts lucy got email attachment let work t...  \n",
       "3       ena fileplan project needs approval approval  \n",
       "4   checkbook budget lucy discuss email later pro...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"X-Folder\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing folders with less than n rows\n",
    "\n",
    "def remove_folders(df, n):\n",
    "    # returns the number of folders containing more than 'n' number of emails\n",
    "    email_count = dict(df['X-Folder'].value_counts())\n",
    "    small_folders = []\n",
    "    for key, val in email_count.items():\n",
    "        if val <= n:\n",
    "            small_folders.append(key)\n",
    "    emails = df.loc[~df['X-Folder'].isin(small_folders)]\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 150\n",
    "df = remove_folders(df, n)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  combining subject and body columns\n",
    "\n",
    "df['text'] = df['subject'] + \" \" + df['body']\n",
    "df.drop([\"body\", \"subject\"], axis = 1, inplace=True)\n",
    "df.head\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing uppercase words, spaces, punctuation\n",
    "def preprocess(x):\n",
    "    # lowercasing all the words\n",
    "    x = x.lower()\n",
    "    \n",
    "    # remove extra new lines\n",
    "    x = re.sub(r'\\n+', ' ', x)\n",
    "    \n",
    "    # removing (replacing with empty spaces actually) all the punctuations\n",
    "    x = re.sub(\"[\"+string.punctuation+\"]\", \" \", x)\n",
    "    \n",
    "    # remove extra white spaces\n",
    "    x = re.sub(r'\\s+', ' ', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(x):\n",
    "    stop = stopwords.words('english')\n",
    "    new = \"\"\n",
    "    for word in x.split():\n",
    "        if word not in stop:\n",
    "            new+= \" \" + word\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop = stopwords.words('english')\n",
    "\n",
    "df.loc[:,'text'] = df.loc[:, 'text'].map(preprocess)\n",
    "\n",
    "# remove stopwords\n",
    "df.loc[:, 'text'] = df.loc[:, 'text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding x-folders that correspond to personal \n",
    "for key,val in df[\"X-Folder\"].value_counts().items():\n",
    "    print(\"{}: {}\".format(key,val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving larger file, containing 400k rows\n",
    "df.to_csv('/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/Dataset/preprocessed.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-accounting",
   "metadata": {},
   "source": [
    "## Creating personal/ professional dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "psychological-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/Dataset/preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "uniform-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into personal / professional dataset\n",
    "personal_words = [\"personal\", \"attachments\", \"misc\"] \n",
    "professional_words = [\"recruiting\", \"corporate\", \"resume\", \"interview\", \"logistics\", \"management\", \"resumes\", \"projects\", \"interviews\", \"conferences\"] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imposed-franchise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4672, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personal_df = df[df[\"X-Folder\"].isin(personal_words)]\n",
    "personal_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chubby-eating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4622</th>\n",
       "      <td>13-12-2000 08:56:00</td>\n",
       "      <td>personal</td>\n",
       "      <td>\"Dell Computer Corp.\" &lt;LB_Electronic_Orders@de...</td>\n",
       "      <td>\"jennifer.medcalf@enron.com\" &lt;jennifer.medcalf...</td>\n",
       "      <td>dell order confirmation dear jennifer medcalf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>14-12-2000 04:55:00</td>\n",
       "      <td>personal</td>\n",
       "      <td>James Wininger</td>\n",
       "      <td>Jennifer Medcalf</td>\n",
       "      <td>brown bag thank dear jennifer thank hosting b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>14-12-2000 04:58:00</td>\n",
       "      <td>personal</td>\n",
       "      <td>Jerome_Alder@Dell.com</td>\n",
       "      <td>jennifer.medcalf@enron.com</td>\n",
       "      <td>dell online order dell enron clickathome orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>14-12-2000 05:22:00</td>\n",
       "      <td>personal</td>\n",
       "      <td>Colleen Koenig</td>\n",
       "      <td>Jennifer Medcalf</td>\n",
       "      <td>update attendees brown bags 12 13 12 14 notic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>15-12-2000 00:32:00</td>\n",
       "      <td>personal</td>\n",
       "      <td>Jennifer N Stewart</td>\n",
       "      <td>Jennifer Medcalf</td>\n",
       "      <td>confirmation order 3253472 hope well forwarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13201</th>\n",
       "      <td>12-01-2002 18:11:45</td>\n",
       "      <td>personal</td>\n",
       "      <td>reservations@sixcontinentshotels.com</td>\n",
       "      <td>Bass, Eric &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=EB...</td>\n",
       "      <td>reservation confirmation thank choosing crown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13202</th>\n",
       "      <td>14-11-2000 08:45:00</td>\n",
       "      <td>personal</td>\n",
       "      <td>\"Bass, Jason\" &lt;Jason.Bass2@COMPAQ.com&gt;</td>\n",
       "      <td>\"Donnita (E-mail)\" &lt;dfranklin@hanovermeasureme...</td>\n",
       "      <td>new work number 281 927 1586 immediately get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13203</th>\n",
       "      <td>31-10-2000 16:39:00</td>\n",
       "      <td>personal</td>\n",
       "      <td>Gwendolyn Gray</td>\n",
       "      <td>Don Black</td>\n",
       "      <td>final associate analyst 2000 prc black prc re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13204</th>\n",
       "      <td>30-10-2000 01:58:00</td>\n",
       "      <td>personal</td>\n",
       "      <td>\"K. Bass\" &lt;daphneco64@bigplanet.com&gt;</td>\n",
       "      <td>Eric Bass &lt;Eric.Bass@enron.com&gt;</td>\n",
       "      <td>aspen ridge hi e sure good see yesterday stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13205</th>\n",
       "      <td>19-09-2000 01:37:00</td>\n",
       "      <td>personal</td>\n",
       "      <td>\"The EnronOnline Games - FREE Registration\" &lt;r...</td>\n",
       "      <td>\"Eric Bass\" &lt;ebass@enron.com&gt;</td>\n",
       "      <td>welcome enrononline games welcome enrononline...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date  X-Folder  \\\n",
       "4622   13-12-2000 08:56:00  personal   \n",
       "4623   14-12-2000 04:55:00  personal   \n",
       "4624   14-12-2000 04:58:00  personal   \n",
       "4625   14-12-2000 05:22:00  personal   \n",
       "4626   15-12-2000 00:32:00  personal   \n",
       "13201  12-01-2002 18:11:45  personal   \n",
       "13202  14-11-2000 08:45:00  personal   \n",
       "13203  31-10-2000 16:39:00  personal   \n",
       "13204  30-10-2000 01:58:00  personal   \n",
       "13205  19-09-2000 01:37:00  personal   \n",
       "\n",
       "                                                  X-From  \\\n",
       "4622   \"Dell Computer Corp.\" <LB_Electronic_Orders@de...   \n",
       "4623                                      James Wininger   \n",
       "4624                               Jerome_Alder@Dell.com   \n",
       "4625                                      Colleen Koenig   \n",
       "4626                                  Jennifer N Stewart   \n",
       "13201               reservations@sixcontinentshotels.com   \n",
       "13202             \"Bass, Jason\" <Jason.Bass2@COMPAQ.com>   \n",
       "13203                                     Gwendolyn Gray   \n",
       "13204               \"K. Bass\" <daphneco64@bigplanet.com>   \n",
       "13205  \"The EnronOnline Games - FREE Registration\" <r...   \n",
       "\n",
       "                                                    X-To  \\\n",
       "4622   \"jennifer.medcalf@enron.com\" <jennifer.medcalf...   \n",
       "4623                                    Jennifer Medcalf   \n",
       "4624                          jennifer.medcalf@enron.com   \n",
       "4625                                    Jennifer Medcalf   \n",
       "4626                                    Jennifer Medcalf   \n",
       "13201  Bass, Eric </O=ENRON/OU=NA/CN=RECIPIENTS/CN=EB...   \n",
       "13202  \"Donnita (E-mail)\" <dfranklin@hanovermeasureme...   \n",
       "13203                                          Don Black   \n",
       "13204                    Eric Bass <Eric.Bass@enron.com>   \n",
       "13205                      \"Eric Bass\" <ebass@enron.com>   \n",
       "\n",
       "                                                    text  \n",
       "4622    dell order confirmation dear jennifer medcalf...  \n",
       "4623    brown bag thank dear jennifer thank hosting b...  \n",
       "4624    dell online order dell enron clickathome orde...  \n",
       "4625    update attendees brown bags 12 13 12 14 notic...  \n",
       "4626    confirmation order 3253472 hope well forwarde...  \n",
       "13201   reservation confirmation thank choosing crown...  \n",
       "13202   new work number 281 927 1586 immediately get ...  \n",
       "13203   final associate analyst 2000 prc black prc re...  \n",
       "13204   aspen ridge hi e sure good see yesterday stay...  \n",
       "13205   welcome enrononline games welcome enrononline...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personal_df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "activated-desert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for choosing Crowne Plaza for your travel needs.\\n\\nYour confirmation number is 66679657.\\nPlease use this number to reference your reservation.\\n\\nGuest Name:          BASS/ERIC\\nHotel:               TIMES SQUARE MANHATTAN, NY\\n                     1605 Broadway\\n                     MANHATTAN, NY 10019 UNITED STATES\\nTelephone Number:    1800 2436969\\n\\nDriving Directions:  N/A\\n\\nArrival Date:        FEB 28, 2002\\nNumber of Nights:    2\\nNumber of Rooms:     1\\nRoom Type:           King Leisure Nonsmoking\\nRate Type:           Great Getaways \\nArrival Rate:        199.95 USD*, per night plus tax**, per room.\\n\\nRate Change:         209.95 USD.  Effective:  Friday, Saturday\\nCheck in Time:       3PM\\nCheck out Time:      12PM\\nGratuity:            EXCLUDES GRATUITY\\nTax:                 13.25% per night and 2.00 USD not included in rate effective February 28, 2002 thru March 2, 2002\\nModify or Cancel by: If you need to cancel your reservation, please do so before 6:00PM on February 27, 2002 or your credit card will be billed for the first night.\\n\\n\\nTo confirm, modify or cancel your reservation (if your rate allows), please visit http://www.sixcontinentshotels.com/crowneplaza?_template=modify_retrieve.html. Should you have any questions regarding your reservation, please contact the hotel directly or your nearest reservation office listed at http://www.sixcontinentshotels.com/sixcontinentshotels?_template=resoffice.html.\\n\\nDream a Million dreams! Now through 01/05/2002 each stay booked online at http://www.sixcontinentshotels.com/priorityclub could win you 1,000,000 Priority Club points.*\\n\\n* Dream a Million Dreams Sweepstakes: No purchase or hotel stay necessary. Open to residents of US and Canada who, as of date of reservation, are Priority Club members, 21 or older. Void in the Province of Quebec and where prohibited. Sweepstakes ends 11:59 PM 01/05/02. \\nVisit http://www.sixcontinentshotels.com/priorityclub/milliondreams for full official rules.\\n\\nIf you are interested in receiving periodic emails with promotional offers from Six Continents Hotels hotel brands, please visit http://www.0mm.com/sch/sch-new.html\\n\\nPlease Note:\\nOnly the reservation as entered into and confirmed by our system will be honored.  Any written or printed confirmation that has been altered may be rejected by the hotel.\\n\\n*  As exchange rates may fluctuate from the time a reservation is made until the actual stay, the confirmed rate is guaranteed in the hotel's base currency.\\n\\n** In the United States, most rates exclude applicable taxes and service charges. In many other destinations, such extras are included in the rate shown. Taxes and other charges will be displayed next to the rate above when applicable.\\n\\nHave a safe and pleasant trip!\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['date'] == \"12-01-2002 18:11:45\"] #13566\n",
    "df.iloc[13566][\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-director",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "broken-newspaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4018, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "professional_df = df[df[\"X-Folder\"].isin(professional_words)]\n",
    "professional_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "russian-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating equal distribution of personal/professional data \n",
    "def make_equal(df1, df2):\n",
    "    remove_n = df2.shape[0] - df1.shape[0]\n",
    "    if remove_n > 0:\n",
    "        # more in professional / df2\n",
    "        drop_indices = np.random.choice(df2.index, remove_n, replace=False)\n",
    "        df2 = df2.drop(drop_indices)\n",
    "    else if remove_n < 0:\n",
    "        drop_indices = np.random.choice(df1.index, -remove_n, replace=False)\n",
    "        df1 = df1.drop(drop_indices)\n",
    "    return df1, df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_df, professional_df = make_equal(personal_df, professional_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "secret-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing rows to \"personal\"\n",
    "personal_df = personal_df.replace(personal_words, \"Personal\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "simplified-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing rows to \"professional\"\n",
    "professional_df = professional_df.replace(professional_words, \"Professional\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "artistic-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining files \n",
    "combined_df = pd.concat([personal_df, professional_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "asian-heath",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8036, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "following-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving as new file \n",
    "combined_df.to_csv('/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/Dataset/professional_personal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting proprocessed.csv into smaller CSVs for Github push\n",
    "\n",
    "preprocessed = \"/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/Dataset/preprocessed.csv\"\n",
    "df_preprocessed = pd.read_csv(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting df into n smaller df\n",
    "\n",
    "number_lines = df_preprocessed.shape[0] \n",
    "rowsize = int(number_lines / 25) \n",
    "cols = list(df_preprocessed.columns)\n",
    "counter = 1\n",
    "for i in range(1,number_lines,rowsize):\n",
    "    new = pd.read_csv(preprocessed, nrows = rowsize, skiprows = i) #skip rows that have been read\n",
    "    out_csv = \"/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/CS4440_project/ML/RyanLe/Datasets/Preprocessed/preprocessed_{}.csv\".format(counter)\n",
    "    counter += 1\n",
    "    new.to_csv(out_csv, index=False, header=cols,  mode='a', chunksize=rowsize)#size of data to append for each loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = pd.read_csv(\"preprocessed_1.csv\")\n",
    "first.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "second = pd.read_csv(\"preprocessed_2.csv\")\n",
    "second.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-winner",
   "metadata": {},
   "source": [
    "## Creating second personal / professional dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/Dataset/preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into personal / professional dataset\n",
    "personal_words = [\"personal\"] \n",
    "professional_words = [\"recruiting\", \"corporate\", \"resume\", \"interview\", \"logistics\", \"management\", \"resumes\", \"projects\", \"interviews\", \"conferences\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_df = df[df[\"X-Folder\"].isin(personal_words)]\n",
    "personal_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "professional_df = df[df[\"X-Folder\"].isin(professional_words)]\n",
    "professional_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_df, professional_df = make_equal(personal_df, professional_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing rows to \"personal\"\n",
    "personal_df = personal_df.replace(personal_words, \"Personal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing rows to \"professional\"\n",
    "professional_df = professional_df.replace(professional_words, \"Professional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining files \n",
    "combined_df = pd.concat([personal_df, professional_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving as new file \n",
    "combined_df.to_csv('/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/Dataset/professional_personal_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-composer",
   "metadata": {},
   "source": [
    "## Creating reply/ no reply dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "weekly-corporation",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-14b07dbc1657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 150\n",
    "df2 = remove_folders(df2, n)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  combining subject and body columns\n",
    "\n",
    "df2['text'] = df2['subject'] + \" \" + df2['body']\n",
    "df2.drop([\"body\", \"subject\"], axis = 1, inplace=True)\n",
    "df2.head\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing uppercase words, spaces, punctuation\n",
    "def preprocess(x):\n",
    "    # lowercasing all the words\n",
    "    x = x.lower()\n",
    "    \n",
    "    # remove extra new lines\n",
    "    x = re.sub(r'\\n+', ' ', x)\n",
    "    punc = string.punctuation.replace(\"?\",\"\")\n",
    "    # removing (replacing with empty spaces actually) all the punctuations\n",
    "    x = re.sub(\"[\"+punc+\"]\", \" \", x)\n",
    "    \n",
    "    # remove extra white spaces\n",
    "    x = re.sub(r'\\s+', ' ', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "def remove_stopwords(x):   \n",
    "    stop = stopwords.words('english')\n",
    "    stop.remove(\"what\")\n",
    "    stop.remove(\"about\")\n",
    "    stop.remove(\"should\")\n",
    "    new = \"\"\n",
    "    for word in x.split():\n",
    "        if word not in stop:\n",
    "            new+= \" \" + word\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop = stopwords.words('english')\n",
    "\n",
    "df2.loc[:,'text'] = df2.loc[:, 'text'].map(preprocess)\n",
    "\n",
    "# remove stopwords\n",
    "df2.loc[:, 'text'] = df2.loc[:, 'text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving larger file, containing 400k rows\n",
    "df2.to_csv('/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/Dataset/preprocessed2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting proprocessed.csv into smaller CSVs for Github push\n",
    "\n",
    "preprocessed2 = \"/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/Dataset/preprocessed2.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting df into n smaller csvs\n",
    "\n",
    "number_lines = df2.shape[0] \n",
    "rowsize = int(number_lines / 25) \n",
    "cols = list(df2.columns)\n",
    "counter = 1\n",
    "for i in range(1,number_lines,rowsize):\n",
    "    new = pd.read_csv(preprocessed2, nrows = rowsize, skiprows = i) #skip rows that have been read\n",
    "    out_csv = \"/Users/ryanle/Desktop/GTSpring2021/CS4440/Project/CS4440_project/ML/RyanLe/Datasets/Preprocessed/preprocessed_{}.csv\".format(counter)\n",
    "    counter += 1\n",
    "    new.to_csv(out_csv, index=False, header=cols,  mode='a', chunksize=rowsize)#size of data to append for each loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
